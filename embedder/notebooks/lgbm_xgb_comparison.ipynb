{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the performances of LightGBM and XGBoost models with three types of embedding (LSI, Word2Vec, FastText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgbm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lsi = pd.read_csv('spark_lsi/X_train_spark_lsi.csv')\n",
    "X_test_lsi = pd.read_csv('spark_lsi/X_test_spark_lsi.csv')\n",
    "y_train_lsi = np.load('spark_lsi/y_train_spark_lsi.npy')\n",
    "y_test_lsi = np.load('spark_lsi/y_test_spark_lsi.npy')\n",
    "y_train_lsi = y_train_lsi.argmax(1) + 1\n",
    "y_test_lsi = y_test_lsi.argmax(1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_word2vec = pd.read_csv('word2vec/X_train_word2vec.csv')\n",
    "X_test_word2vec = pd.read_csv('word2vec/X_test_word2vec.csv')\n",
    "y_train_word2vec = np.load('word2vec/y_train_word2vec.npy')\n",
    "y_test_word2vec = np.load('word2vec/y_test_word2vec.npy')\n",
    "y_train_word2vec = y_train_word2vec.argmax(1) + 1\n",
    "y_test_word2vec = y_test_word2vec.argmax(1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fasttext = pd.read_csv('fasttext/X_train_fasttext.csv')\n",
    "X_test_fasttext = pd.read_csv('fasttext/X_test_fasttext.csv')\n",
    "y_train_fasttext = np.load('fasttext/y_train_fasttext.npy')\n",
    "y_test_fasttext = np.load('fasttext/y_test_fasttext.npy')\n",
    "y_train_fasttext = y_train_fasttext.argmax(1) + 1\n",
    "y_test_fasttext = y_test_fasttext.argmax(1) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_classifier = lgbm.LGBMClassifier(boosting_type='dart', n_estimators=5000, learning_rate=0.1, max_depth=-1, num_leaves=16, subsample=0.9, colsample_bytree=0.9, subsample_freq=1, uniform_drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy obtained with lgbm and lsi is 0.5230894973436861\n"
     ]
    }
   ],
   "source": [
    "lgbm_classifier.fit(X_train_lsi,y_train_lsi)\n",
    "y_pred_lsi = lgbm_classifier.predict(X_test_lsi)\n",
    "accuracy = accuracy_score(y_test_lsi, y_pred_lsi)\n",
    "print(f'The accuracy obtained with lgbm and lsi is {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy obtained with lgbm and word2vec is 0.5623212096444626\n"
     ]
    }
   ],
   "source": [
    "lgbm_classifier.fit(X_train_word2vec,y_train_word2vec)\n",
    "y_pred_word2vec = lgbm_classifier.predict(X_test_word2vec)\n",
    "accuracy = accuracy_score(y_test_word2vec, y_pred_word2vec)\n",
    "print(f'The accuracy obtained with lgbm and word2vec is {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy obtained with lgbm and fasttext is 0.4495300367797303\n"
     ]
    }
   ],
   "source": [
    "lgbm_classifier.fit(X_train_fasttext,y_train_fasttext)\n",
    "y_pred_fasttext = lgbm_classifier.predict(X_test_fasttext)\n",
    "accuracy = accuracy_score(y_test_fasttext, y_pred_fasttext)\n",
    "print(f'The accuracy obtained with lgbm and fasttext is {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier = xgb.XGBClassifier(n_estimators=1000, learning_rate=0.1, max_depth=5, subsample=0.9, colsample_bytree = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy obtained with xgboost and lsi is 0.5190028606456886\n"
     ]
    }
   ],
   "source": [
    "xgb_classifier.fit(X_train_lsi,y_train_lsi)\n",
    "y_pred_lsi = xgb_classifier.predict(X_test_lsi)\n",
    "accuracy = accuracy_score(y_test_lsi, y_pred_lsi)\n",
    "print(f'The accuracy obtained with xgboost and lsi is {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy obtained with xgboost and word2vec is 0.5557825909276666\n"
     ]
    }
   ],
   "source": [
    "xgb_classifier.fit(X_train_word2vec,y_train_word2vec)\n",
    "y_pred_word2vec = xgb_classifier.predict(X_test_word2vec)\n",
    "accuracy = accuracy_score(y_test_word2vec, y_pred_word2vec)\n",
    "print(f'The accuracy obtained with xgboost and word2vec is {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy obtained with xgboost and fasttext is 0.4446260727421332\n"
     ]
    }
   ],
   "source": [
    "xgb_classifier.fit(X_train_fasttext,y_train_fasttext)\n",
    "y_pred_fasttext = xgb_classifier.predict(X_test_fasttext)\n",
    "accuracy = accuracy_score(y_test_fasttext, y_pred_fasttext)\n",
    "print(f'The accuracy obtained with xgboost and fasttext is {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best result is achieved using Light Gradient Boosting Machine on the Word2Vec embedding matrix, which confirms the results found in the `embedding_performance_comparison.ipynb` notebook. The latter states that Word2Vec and LSI embeddings enable to achieve similar performances in guessing the rating of reviews.\n",
    "\n",
    "However, the best accuracy (59%) is achieved using a tuned Neural Network on a Word2Vec embedding matrix."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
