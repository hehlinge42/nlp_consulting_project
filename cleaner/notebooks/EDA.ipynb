{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis - TripAdvisor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from wordcloud import WordCloud\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_dict_generator(keywords, keywords_dict):\n",
    "    \"\"\"Creation of a dict containing all of the keywords. \"\"\"\n",
    "    for keyword in keywords:\n",
    "        if keyword not in keywords_dict:\n",
    "            keywords_dict[keyword] = 1\n",
    "        else:\n",
    "            keywords_dict[keyword] += 1\n",
    "\n",
    "def col_evaluation(ls, col_name):\n",
    "    \"\"\" Function used to check if a given cuisine is present in the list of the 'cuisine' column. It is\n",
    "    used in a parallelised manner.\"\"\"\n",
    "    if col_name in ls:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val\n",
    "            \n",
    "def generate_cuisine_cols(df, cuisine_dict):\n",
    "    \"\"\" Creation of the columns containing all of the cuisine types in a dataframe. \"\"\"\n",
    "    for col_name in cuisine_dict:\n",
    "        df[col_name] = df['cuisine'].apply(lambda x: col_evaluation(x, col_name))\n",
    "    return df44\n",
    "\n",
    "def keywords_list_parser(ls):\n",
    "    \"\"\"Parses a given list of 3 keywords to determine the main cuisine (ex: Indian, British), the food specificity \n",
    "    (Vegan, serving seafood...) and whether the restaurant has unique features (ex: if it is a bar, a pub...). Each\n",
    "     keyword is read in order to first find the specificity and the feature. For the cuisine, the algorithm first\n",
    "     tries to find a 'tier one cuisine' (i.e a very specific type of cuisine) before moving on to a 'tier two cuisine' \n",
    "     (i.e a more global type of cuisine such as 'European'). For each category, a hardcoded list of entries is read. \"\"\"\n",
    "    \n",
    "    place_type = None\n",
    "    food_spec = None\n",
    "    cuisine_t1 = None\n",
    "    cuisine_t2 = None\n",
    "\n",
    "    found_place = False\n",
    "    found_spec = False\n",
    "    found_cuisine_t1 = False\n",
    "    found_cuisine_t2 = False\n",
    "\n",
    "    place_type_ls = ['Bar', 'Pub', 'Cafe', 'Street food', 'Steakhouse']\n",
    "\n",
    "    food_specifity = ['Vegan', 'Gluten Free Options', 'Healthy', 'Fast food', 'Barbecue', 'Seafood',\n",
    "                      'Fusion', 'Contemporary', 'Halal']\n",
    "    \n",
    "    cuisine_tier_one = ['British', 'French', 'Italian', 'Indian', 'Spanish', 'Turkish',\n",
    "                        'South American', 'Other European', 'Lebanese', 'Moroccan', 'American',\n",
    "                        'Thai', 'African'] \n",
    "\n",
    "    cuisine_tier_two = ['Asian', 'European', 'Other European', 'Middle Eastern', 'International']\n",
    "    \n",
    "    for word in ls:\n",
    "        \n",
    "        if (word in place_type_ls) and (found_place == False):\n",
    "            place_type = word\n",
    "            found_place = True\n",
    "        if (word in food_specifity) and (found_spec == False):\n",
    "            food_spec = word\n",
    "            found_spec = True\n",
    "        if (word in cuisine_tier_one) and (found_cuisine_t1 == False):\n",
    "            cuisine_t1 = word\n",
    "            found_cuisine_t1 = True\n",
    "        if (word in cuisine_tier_two) and (found_cuisine_t2 == False):\n",
    "            cuisine_t2 = word\n",
    "            found_cuisine_t2 = True\n",
    "        \n",
    "    if cuisine_t1 == None:\n",
    "        cuisine = cuisine_t2\n",
    "    else:\n",
    "        cuisine = cuisine_t1\n",
    "            \n",
    "    return [cuisine, food_spec, place_type]\n",
    "    \n",
    "\n",
    "def simplify_keywords(keyword_ls, keyword_dict):\n",
    "    \"\"\"Simplifies keywords thanks to a hardcoded dict given as input. It is used to assemble close cuisines and \n",
    "    features into a single entry to enhance the analysis (ex : Sri Lankan and Indian are grouped).\"\"\"\n",
    "    new_keyword_ls = [keyword_dict.get(item,item) for item in keyword_ls]\n",
    "    return new_keyword_ls\n",
    "    \n",
    "def score_builder(text):\n",
    "    \"\"\"A unified ranking score is built by considering this formula : \n",
    "    \n",
    "    score = (total_entries - rank + 1)/total_entries\n",
    "    \n",
    "    Therefore, restaurants ranking can be compared across different locations. \"\"\"\n",
    "    \n",
    "    if text != 'Ranking not found':\n",
    "        rank = int(text[1])\n",
    "        total_entries = int(text.split()[2].replace(',',''))\n",
    "        score = (total_entries - rank + 1) / total_entries\n",
    "        return round(score, 3)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def location_extractor(text):\n",
    "    \"\"\"Used to extract the neighborhood where the restaurant is located.\"\"\"\n",
    "    if text != 'Ranking not found':\n",
    "        return text.split()[-1]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def identify_coordinates(address):\n",
    "    \"\"\"This functions performs an API call with the scrapped address of the restaurant to the OpenStreetMap API.\n",
    "    A longitude and a latitude are then returned.\"\"\"\n",
    "    \n",
    "    # Try using full address\n",
    "    target_url = 'https://nominatim.openstreetmap.org/search?q=' + address + '&format=json'\n",
    "    target_url = target_url.replace(',', '%2C')\n",
    "    target_url = target_url.replace(' ', '+')\n",
    "\n",
    "    r = requests.get(target_url)\n",
    "    found_coordinates = True\n",
    "    if r.status_code==200:\n",
    "        try:\n",
    "            coordinates = r.json()[0]\n",
    "            latitude, longitude = coordinates['lat'], coordinates['lon']\n",
    "            \n",
    "        except:\n",
    "            #print(f'Address not found for: {target_url}')\n",
    "            latitude, longitude = None, None\n",
    "            found_coordinates = False\n",
    "            \n",
    "    else:\n",
    "        print(f'Error {status_code} ocurred on the request')\n",
    "        latitude, longitude, found_coordinates = identify_coordinates_postcode(address)\n",
    "    return (latitude, longitude, found_coordinates) \n",
    "\n",
    "def identify_coordinates_postcode(address):\n",
    "    # If address fails then use postcode to get approximate lat and long\n",
    "    postcode = get_postcode(address)\n",
    "    \n",
    "    target_url = 'https://nominatim.openstreetmap.org/search?q=' + postcode + '&format=json'\n",
    "    target_url = target_url.replace(',', '%2C')\n",
    "    target_url = target_url.replace(' ', '+')\n",
    "\n",
    "    r = requests.get(target_url)\n",
    "    found_coordinates = True\n",
    "    if r.status_code==200:\n",
    "        try:\n",
    "            coordinates = r.json()[0]\n",
    "            latitude, longitude = coordinates['lat'], coordinates['lon']\n",
    "            \n",
    "        except:\n",
    "            #print(f'Address not found for: {target_url}')\n",
    "            latitude, longitude = None, None\n",
    "            found_coordinates = False\n",
    "            \n",
    "    else:\n",
    "        print(f'Error {status_code} ocurred on the request')\n",
    "        latitude, longitude, found_coordinates = None, None, False\n",
    "    return (latitude, longitude, found_coordinates) \n",
    "    \n",
    "def get_postcode(address):\n",
    "    splits = address.split(' ')\n",
    "    postcode = []\n",
    "\n",
    "    for idx, split in enumerate(splits):\n",
    "        if split.upper() == split:\n",
    "            if len(split) == 3 and len(postcode) == 0:\n",
    "                postcode.append(split)\n",
    "                first_part = idx\n",
    "            elif len(split) == 3 and len(postcode) != 0:\n",
    "                if idx == first_part + 1:\n",
    "                    postcode.append(split)\n",
    "                    # finish\n",
    "                else:\n",
    "                    first_part = idx\n",
    "                    postcode[0] = split\n",
    "    return postcode\n",
    "\n",
    "def haversine_dist_to_bokan(lat, lon):\n",
    "    \"\"\"Computes the Haversine distance of a given restaurant to the Bokan, given a longitude and a latitude.\"\"\"\n",
    "\n",
    "    deg_to_rad = lambda x: x * np.pi/180\n",
    "    \n",
    "    bokan_lat = 51.501244\n",
    "    bokan_lon = -0.023363\n",
    "    \n",
    "    R = 6371 # Radius of the earth in km\n",
    "    deg_lat = deg_to_rad(lat - bokan_lat)\n",
    "    deg_lon = deg_to_rad(lon - bokan_lon) \n",
    "    a = np.sin(deg_lat/2) * np.sin(deg_lat/2) + np.cos(deg_to_rad(lat)) * np.cos(deg_to_rad(bokan_lat)) * np.sin(deg_lon/2) * np.sin(deg_lon/2)\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    d = R * c ## Distance in km\n",
    "    return np.round(d, 3)\n",
    "\n",
    "def process_distances(df, print_output=250):\n",
    "    \"\"\"Determines all of the distances between the restaurants and the bokan. It also returns the number of \n",
    "    restaurants which address couldn't be used to find the latitude and the longitude.\"\"\"\n",
    "    adress_list = df['address'].tolist()\n",
    "    not_found_counter = 0\n",
    "    for counter, address in enumerate(adress_list):\n",
    "        lat, lon, found_coordinates = identify_coordinates(address)\n",
    "        if found_coordinates == False:\n",
    "            not_found_counter += 1\n",
    "        if counter%print_output==0:\n",
    "            print(f'{counter}/{len(df)} restaurant coordinates have been processed.')\n",
    "        adress_list[counter] = [lat, lon]\n",
    "    print(f'Finished determining coordinates. {not_found_counter}/{len(df)} coordinates have not been found.')\n",
    "    \n",
    "    np_coords = np.asarray(adress_list, dtype=np.float32)\n",
    "    np_lat, np_lon = np_coords[:,0], np_coords[:,1]\n",
    "    distances = haversine_dist_to_bokan(np_lat, np_lon)\n",
    "\n",
    "    return distances\n",
    "\n",
    "def handle_duplicate_addresses(df):\n",
    "    df.loc[df[['address']].duplicated(), 'address'] = df.loc[df[['address']].duplicated(), 'address'] + ' bis'\n",
    "    return df\n",
    "    \n",
    "\n",
    "def cleaning_pipeline(df, keywords_renaming_dict, parse_distances=False):\n",
    "    \"\"\"Performs all of the cleaning operations. The process_distances parameter is set on False by default as the \n",
    "    number of API calls can run for a substantial amount of time.\"\"\"\n",
    "    cuisine_dict = {}\n",
    "    df_restaurants_cuisine = df.copy()\n",
    "    df_restaurants_cuisine = df_restaurants_cuisine.rename(columns={'cuisine':'keywords'})                                                                                   \n",
    "    # Creates a frequency dictionary containing the occurence of all types of cuisine\n",
    "    df_restaurants_cuisine['keywords'].apply(lambda x: freq_dict_generator(x, cuisine_dict))\n",
    "    \n",
    "    # Converting reviews as int\n",
    "    df_restaurants_cuisine['nb_reviews'] = df_restaurants_cuisine['nb_reviews'].str.replace(',','').astype('int64')\n",
    "    \n",
    "    # Creates a ranking score in order to compare restaurants competing among a different amount of restaurants\n",
    "    # in a neighborhood. The score of the restaurant ranked i among n restaurants is as such : \n",
    "    # Score = (n - i + 1) / n\n",
    "    df_restaurants_cuisine['score'] = df_restaurants_cuisine['ranking'].apply(lambda x: score_builder(x))\n",
    "    \n",
    "    # Extracts the neighborhood where the restaurant is located\n",
    "    df_restaurants_cuisine['neighborhood'] = df_restaurants_cuisine['ranking'].apply(lambda x: location_extractor(x))\n",
    "    \n",
    "    # Simplifies and groups the original keywords to enhance the analysis\n",
    "    df_restaurants_cuisine['keywords'] = df_restaurants_cuisine['keywords'].apply(lambda x: simplify_keywords(x, \n",
    "                                                                                            keywords_renaming_dict))\n",
    "    # Separates the keywords into useful categories used to performed detailled analysis\n",
    "    df_restaurants_cuisine['cuisine'] = None\n",
    "    df_restaurants_cuisine['food_specificity'] = None\n",
    "    df_restaurants_cuisine['place_type'] = None\n",
    "    key_res = df_restaurants_cuisine['keywords'].apply(keywords_list_parser)\n",
    "    df_restaurants_cuisine[['cuisine','food_specificity','place_type']] = pd.DataFrame(key_res.tolist(), index=df_restaurants_cuisine.index)\n",
    "    \n",
    "    \n",
    "    # Computes the distance in kilometers between the Bokan and the scrapped restaurant\n",
    "    if parse_distances:\n",
    "        df_restaurants_cuisine['distance_to_bokan'] = process_distances(df_restaurants_cuisine)\n",
    "    \n",
    "    df_restaurants_cuisine = handle_duplicate_addresses(df_restaurants_cuisine)\n",
    "    # Used to generate the columns indicating the cuisine of the restaurant - DEPRECATED\n",
    "    #df_restaurants_cuisine = generate_cuisine_cols(df_restaurants_cuisine, cuisine_dict)\n",
    "    \n",
    "    return df_restaurants_cuisine, cuisine_dict\n",
    "\n",
    "def cuisine_stats(df, target_col='cuisine', stats='mean', \n",
    "                  cols=['cuisine', 'nb_reviews', 'min_price', 'max_price', 'rating', 'score', 'neighborhood']):\n",
    "    \"\"\" Generate statistics on restaurants, using a column such as the type of cuisine or the special features. \"\"\"\n",
    "    df_res = df[cols].groupby(by=target_col)\n",
    "    temp = df_res.size()\n",
    "    if stats == 'mean':\n",
    "        df_res = df_res.mean()\n",
    "        rename_dict = {col:'mean_' + col for col in df_res.columns}\n",
    "    elif stats == 'median':\n",
    "        df_res = df_res.median()\n",
    "        rename_dict = {col:'median_' + col for col in df_res.columns}\n",
    "    elif stats == 'std':\n",
    "        df_res = df_res.std()\n",
    "        rename_dict = {col:'std_' + col for col in df_res.columns}\n",
    "    df_res = df_res.rename(columns=rename_dict)\n",
    "    df_res['nb_restaus'] = temp.tolist()\n",
    "    cols = df_res.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    df_res = df_res[cols]\n",
    "#     f = lambda x: cuisine_name if x==1 else 'Other cuisines'\n",
    "#     df_res.index = list(map(f, df_res.index))\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = os.path.join('..', '..', 'scraper', 'scraped_data', 'merged_data')\n",
    "\n",
    "restaurants_path = os.path.join('..', '..', 'scraper', 'scraper_restaurants', 'scraped_data', 'restaurants', 'restaurants_run_1.json')\n",
    "review_path = os.path.join(root_path, 'merged_reviews.json')\n",
    "users_path = os.path.join(root_path, 'merged_users.json')\n",
    "\n",
    "df_restaurants = pd.read_json(restaurants_path, lines=True)\n",
    "restaurants = list(df_restaurants['restaurant_id'])\n",
    "df_restaurants = df_restaurants.set_index('restaurant_id')\n",
    "\n",
    "df_reviews = pd.read_json(review_path, lines=True)\n",
    "df_users = pd.read_json(users_path, lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/13405 restaurant coordinates have been processed.\n",
      "250/13405 restaurant coordinates have been processed.\n",
      "500/13405 restaurant coordinates have been processed.\n",
      "750/13405 restaurant coordinates have been processed.\n",
      "1000/13405 restaurant coordinates have been processed.\n",
      "1250/13405 restaurant coordinates have been processed.\n",
      "1500/13405 restaurant coordinates have been processed.\n",
      "1750/13405 restaurant coordinates have been processed.\n",
      "2000/13405 restaurant coordinates have been processed.\n",
      "2250/13405 restaurant coordinates have been processed.\n",
      "2500/13405 restaurant coordinates have been processed.\n",
      "2750/13405 restaurant coordinates have been processed.\n",
      "3000/13405 restaurant coordinates have been processed.\n",
      "3250/13405 restaurant coordinates have been processed.\n",
      "3500/13405 restaurant coordinates have been processed.\n",
      "3750/13405 restaurant coordinates have been processed.\n",
      "4000/13405 restaurant coordinates have been processed.\n",
      "4250/13405 restaurant coordinates have been processed.\n",
      "4500/13405 restaurant coordinates have been processed.\n",
      "4750/13405 restaurant coordinates have been processed.\n",
      "5000/13405 restaurant coordinates have been processed.\n",
      "5250/13405 restaurant coordinates have been processed.\n",
      "5500/13405 restaurant coordinates have been processed.\n",
      "5750/13405 restaurant coordinates have been processed.\n",
      "6000/13405 restaurant coordinates have been processed.\n",
      "6250/13405 restaurant coordinates have been processed.\n",
      "6500/13405 restaurant coordinates have been processed.\n",
      "6750/13405 restaurant coordinates have been processed.\n",
      "7000/13405 restaurant coordinates have been processed.\n",
      "7250/13405 restaurant coordinates have been processed.\n",
      "7500/13405 restaurant coordinates have been processed.\n",
      "7750/13405 restaurant coordinates have been processed.\n",
      "8000/13405 restaurant coordinates have been processed.\n",
      "8250/13405 restaurant coordinates have been processed.\n",
      "8500/13405 restaurant coordinates have been processed.\n",
      "8750/13405 restaurant coordinates have been processed.\n",
      "9000/13405 restaurant coordinates have been processed.\n",
      "9250/13405 restaurant coordinates have been processed.\n",
      "9500/13405 restaurant coordinates have been processed.\n",
      "9750/13405 restaurant coordinates have been processed.\n",
      "10000/13405 restaurant coordinates have been processed.\n",
      "10250/13405 restaurant coordinates have been processed.\n",
      "10500/13405 restaurant coordinates have been processed.\n",
      "10750/13405 restaurant coordinates have been processed.\n",
      "11000/13405 restaurant coordinates have been processed.\n",
      "11250/13405 restaurant coordinates have been processed.\n",
      "11500/13405 restaurant coordinates have been processed.\n",
      "11750/13405 restaurant coordinates have been processed.\n",
      "12000/13405 restaurant coordinates have been processed.\n",
      "12250/13405 restaurant coordinates have been processed.\n",
      "12500/13405 restaurant coordinates have been processed.\n",
      "12750/13405 restaurant coordinates have been processed.\n",
      "13000/13405 restaurant coordinates have been processed.\n",
      "13250/13405 restaurant coordinates have been processed.\n",
      "Finished determining coordinates. 2916/13405 coordinates have not been found.\n"
     ]
    }
   ],
   "source": [
    "keywords_renaming_dict = {\n",
    "    'Southern-Italian':'Italian', 'Sicilian':'Italian', 'Tuscan':'Italian', 'Neapolitan':'Italian',\n",
    "    'Central-Italian':'Italian', 'Pizza':'Italian', 'Polish':'European', 'Belgian':'European',\n",
    "    'German':'European', 'Eastern European':'European', 'Portuguese':'European',\n",
    "    'Greek':'European', 'Hong Kong':'Chinese','Cantonese':'Chinese', 'Sushi':'Japanese', \n",
    "    'Malaysian':'Asian', 'Tibetan':'Asian', 'Vietnamese':'Asian', 'Latin':'South American', \n",
    "    'Argentinian':'South American', 'Mexican':'South American', 'Brazilian':'South American',\n",
    "    'Colombian':'South American', 'Vegetarian Friendly':'Vegan', 'Vegan Options':'Vegan', 'Persian':'Middle Eastern',\n",
    "    'Afghani':'Middle Eastern', 'Deli':'Indian', 'Sri Lankan':'Indian', 'Pakistani':'Indian', 'Balti':'Indian',\n",
    "    'Nepalese':'Indian', 'Jamaican':'African', 'Carribean':'African', 'Cajun & Creole':'African',\n",
    "    'Moroccan':'African', 'Brew Pub':'Pub', 'Gastropub':'Pub', 'Grill':'Barbecue'}\n",
    "\n",
    "df_restaurants_cuisine, cuisine_dict = cleaning_pipeline(df_restaurants, keywords_renaming_dict, parse_distances=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Grill': 302, 'Pakistani': 86, 'Afghani': 31, 'Indian': 1567, 'Asian': 2123, 'Vegetarian Friendly': 3163, 'Steakhouse': 212, 'Argentinian': 35, 'Latin': 64, 'Bar': 1691, 'Pizza': 1066, 'British': 3037, 'Italian': 1475, 'Deli': 88, 'Lebanese': 259, 'Cafe': 1384, 'Mediterranean': 1448, 'European': 1602, 'Balti': 295, 'Spanish': 155, 'Vegan Options': 573, 'International': 367, 'Contemporary': 159, 'Japanese': 421, 'Middle Eastern': 552, 'Sushi': 313, 'Thai': 357, 'Healthy': 212, 'Nepalese': 60, 'French': 311, 'Gluten Free Options': 205, 'Fast food': 926, 'Chinese': 638, 'Cantonese': 140, 'African': 66, 'Moroccan': 46, 'Turkish': 469, 'Persian': 97, 'Seafood': 405, 'Barbecue': 190, 'Pub': 1148, 'Caribbean': 123, 'Mexican': 106, 'Brazilian': 53, 'Bakeries': 4, 'Fusion': 79, 'Brew Pub': 47, 'Sri Lankan': 56, 'Greek': 111, 'Polish': 41, 'Eastern European': 58, 'Belgian': 12, 'German': 20, 'Sicilian': 15, 'Southern-Italian': 13, 'Tibetan': 3, 'American': 419, 'Gastropub': 51, 'Street Food': 52, 'Vietnamese': 75, 'Ethiopian': 12, 'Halal': 123, 'Egyptian': 5, 'Taiwanese': 14, 'Diner': 84, 'Wine Bar': 86, 'Scandinavian': 9, 'Danish': 3, 'Neapolitan': 31, 'Korean': 58, 'Philippine': 13, 'Portuguese': 71, 'Soups': 44, 'Hong Kong': 36, 'Quick Bites': 95, 'Indonesian': 6, 'Scottish': 5, 'Jamaican': 46, 'Malaysian': 30, 'Bangladeshi': 82, 'Central American': 9, 'Campania': 5, 'South American': 43, 'Szechuan': 27, 'Singaporean': 7, 'Australian': 16, 'Israeli': 28, 'Colombian': 7, 'Beer restaurants': 1, 'Burmese': 2, 'Basque': 2, 'Arabic': 24, 'Irish': 23, 'Welsh': 3, 'Dining bars': 5, 'Peruvian': 21, 'Dessert': 10, 'Canadian': 1, 'Ukrainian': 2, 'Central European': 11, 'Dutch': 5, 'Swedish': 5, 'Beijing Specialties ': 3, 'Kosher': 16, 'Cajun & Creole': 5, 'Austrian': 6, 'Croatian': 2, 'Romanian': 12, 'Uzbek': 3, 'Polynesian': 1, 'Hawaiian': 2, 'Nonya/Malaysian': 1, 'Tunisian': 2, 'Sardinian': 3, 'Russian': 5, 'Puerto Rican': 1, 'Armenian': 1, 'Central Asian': 4, 'Southwestern': 8, 'Northern-Italian': 4, 'Shanghai': 3, 'Central-Italian': 7, 'Speciality Food Market': 1, 'Georgian': 5, 'Cuban': 4, 'Japanese Fusion': 4, 'Hungarian': 1, 'Romana': 4, 'Lazio': 3, 'Nigerian': 1, 'Venezuelan': 2, 'Emilian': 1, 'Swiss': 2, 'New Zealand': 1, 'Albanian': 1, 'Catalan': 1, 'Tuscan': 1}\n"
     ]
    }
   ],
   "source": [
    "print(cuisine_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation of a restaurant's reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_id = \"0\"\n",
    "while (restaurant_id not in restaurants):\n",
    "    try:\n",
    "        restaurant_id = int(input(\"Enter restaurant id from 1 to 143 : \"))\n",
    "    except:\n",
    "        print(\"Please enter int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_csv = str(restaurant_id) + '_word_freq.csv'\n",
    "target_csv_path = os.path.join('..', 'cleaned_data', 'restaurants_tfidf', target_csv)\n",
    "\n",
    "df_tfidf = pd.read_csv(target_csv_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_tfidf_mean = df_tfidf.mean().sort_values(ascending=False).to_frame(name='tfidf mean')\n",
    "df_tfidf_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_tfidf_mean[:15].plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordcloud visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "target_img = str(restaurant_id) + '_word_cloud.png'\n",
    "target_img_path = os.path.join('..', 'cleaned_data', 'restaurant_wordclouds', target_img)\n",
    "img = plt.imread(target_img_path)\n",
    "\n",
    "plt.figure(figsize=(12,16))\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other wordclouds and TF-IDF can be found in the dedicated folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global restaurant analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def filtering_dataframe(df, column, terms):\n",
    "    \n",
    "#     df = df[df[''].str.findall()]\n",
    "#     return df\n",
    "\n",
    "# def generate_wordcloud(df, idx, directory, mask):\n",
    "#     #filename = directory + str(idx) + \"_word_cloud.png\"\n",
    "\n",
    "#     df_mean = df.mean().sort_values(ascending=False).to_frame(name='tfidf mean')\n",
    "#     dict_words_tfidf = df_mean[df_mean['tfidf mean'] != 0].to_dict()['tfidf mean']\n",
    "\n",
    "#     wordcloud = WordCloud(height=600, width=800, background_color=\"white\",\n",
    "#         colormap='Blues', max_words=100, mask=mask,\n",
    "#         contour_width=0.5, contour_color='lightsteelblue')\n",
    "#     wordcloud.generate_from_frequencies(frequencies=dict_words_tfidf)\n",
    "#     wordcloud.to_file(filename)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_restaurants_cuisine.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_restaurants_cuisine.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = cuisine_stats(df_restaurants_cuisine, stats='mean')\n",
    "df_stats.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_restaurants_cuisine.to_csv('cleaned_restaus.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
